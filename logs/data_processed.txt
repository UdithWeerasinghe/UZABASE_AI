2025-03-06 17:30:24,277 - process_data_all - INFO - Process started
2025-03-06 17:30:27,049 - py4j.java_gateway - DEBUG - GatewayClient.address is deprecated and will be removed in version 1.0. Use GatewayParameters instead.
2025-03-06 17:30:27,050 - py4j.clientserver - DEBUG - Command to send: A
f1e8604e450cd81dcbda5696091d20eaa7b1b076d12fd2229c32ff2bae579c8f

2025-03-06 17:30:27,057 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:27,057 - py4j.clientserver - DEBUG - Command to send: j
i
rj
org.apache.spark.SparkConf
e

2025-03-06 17:30:27,076 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:27,076 - py4j.clientserver - DEBUG - Command to send: j
i
rj
org.apache.spark.api.java.*
e

2025-03-06 17:30:27,077 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:27,077 - py4j.clientserver - DEBUG - Command to send: j
i
rj
org.apache.spark.api.python.*
e

2025-03-06 17:30:27,078 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:27,079 - py4j.clientserver - DEBUG - Command to send: j
i
rj
org.apache.spark.ml.python.*
e

2025-03-06 17:30:27,079 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:27,080 - py4j.clientserver - DEBUG - Command to send: j
i
rj
org.apache.spark.mllib.api.python.*
e

2025-03-06 17:30:27,080 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:27,081 - py4j.clientserver - DEBUG - Command to send: j
i
rj
org.apache.spark.resource.*
e

2025-03-06 17:30:27,081 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:27,082 - py4j.clientserver - DEBUG - Command to send: j
i
rj
org.apache.spark.sql.*
e

2025-03-06 17:30:27,082 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:27,082 - py4j.clientserver - DEBUG - Command to send: j
i
rj
org.apache.spark.sql.api.python.*
e

2025-03-06 17:30:27,083 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:27,083 - py4j.clientserver - DEBUG - Command to send: j
i
rj
org.apache.spark.sql.hive.*
e

2025-03-06 17:30:27,084 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:27,084 - py4j.clientserver - DEBUG - Command to send: j
i
rj
scala.Tuple2
e

2025-03-06 17:30:27,085 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:27,085 - py4j.clientserver - DEBUG - Command to send: r
u
SparkConf
rj
e

2025-03-06 17:30:27,086 - py4j.clientserver - DEBUG - Answer received: !ycorg.apache.spark.SparkConf
2025-03-06 17:30:27,086 - py4j.clientserver - DEBUG - Command to send: i
org.apache.spark.SparkConf
bTrue
e

2025-03-06 17:30:27,096 - py4j.clientserver - DEBUG - Answer received: !yro0
2025-03-06 17:30:27,096 - py4j.clientserver - DEBUG - Command to send: c
o0
set
sspark.app.name
sWordProcessing
e

2025-03-06 17:30:27,102 - py4j.clientserver - DEBUG - Answer received: !yro1
2025-03-06 17:30:27,102 - py4j.clientserver - DEBUG - Command to send: c
o0
set
sspark.hadoop.fs.file.impl
sorg.apache.hadoop.fs.LocalFileSystem
e

2025-03-06 17:30:27,103 - py4j.clientserver - DEBUG - Answer received: !yro2
2025-03-06 17:30:27,103 - py4j.clientserver - DEBUG - Command to send: c
o0
contains
sspark.serializer.objectStreamReset
e

2025-03-06 17:30:27,103 - py4j.clientserver - DEBUG - Answer received: !ybfalse
2025-03-06 17:30:27,105 - py4j.clientserver - DEBUG - Command to send: c
o0
set
sspark.serializer.objectStreamReset
s100
e

2025-03-06 17:30:27,105 - py4j.clientserver - DEBUG - Answer received: !yro3
2025-03-06 17:30:27,106 - py4j.clientserver - DEBUG - Command to send: c
o0
contains
sspark.rdd.compress
e

2025-03-06 17:30:27,107 - py4j.clientserver - DEBUG - Answer received: !ybfalse
2025-03-06 17:30:27,107 - py4j.clientserver - DEBUG - Command to send: c
o0
set
sspark.rdd.compress
sTrue
e

2025-03-06 17:30:27,107 - py4j.clientserver - DEBUG - Answer received: !yro4
2025-03-06 17:30:27,109 - py4j.clientserver - DEBUG - Command to send: c
o0
contains
sspark.master
e

2025-03-06 17:30:27,109 - py4j.clientserver - DEBUG - Answer received: !ybtrue
2025-03-06 17:30:27,110 - py4j.clientserver - DEBUG - Command to send: c
o0
contains
sspark.app.name
e

2025-03-06 17:30:27,110 - py4j.clientserver - DEBUG - Answer received: !ybtrue
2025-03-06 17:30:27,111 - py4j.clientserver - DEBUG - Command to send: c
o0
contains
sspark.master
e

2025-03-06 17:30:27,111 - py4j.clientserver - DEBUG - Answer received: !ybtrue
2025-03-06 17:30:27,112 - py4j.clientserver - DEBUG - Command to send: c
o0
get
sspark.master
e

2025-03-06 17:30:27,113 - py4j.clientserver - DEBUG - Answer received: !yslocal[*]
2025-03-06 17:30:27,114 - py4j.clientserver - DEBUG - Command to send: c
o0
contains
sspark.app.name
e

2025-03-06 17:30:27,114 - py4j.clientserver - DEBUG - Answer received: !ybtrue
2025-03-06 17:30:27,115 - py4j.clientserver - DEBUG - Command to send: c
o0
get
sspark.app.name
e

2025-03-06 17:30:27,116 - py4j.clientserver - DEBUG - Answer received: !ysWordProcessing
2025-03-06 17:30:27,116 - py4j.clientserver - DEBUG - Command to send: c
o0
contains
sspark.home
e

2025-03-06 17:30:27,117 - py4j.clientserver - DEBUG - Answer received: !ybfalse
2025-03-06 17:30:27,117 - py4j.clientserver - DEBUG - Command to send: c
o0
getAll
e

2025-03-06 17:30:27,117 - py4j.clientserver - DEBUG - Answer received: !yto5
2025-03-06 17:30:27,117 - py4j.clientserver - DEBUG - Command to send: a
e
o5
e

2025-03-06 17:30:27,118 - py4j.clientserver - DEBUG - Answer received: !yi9
2025-03-06 17:30:27,118 - py4j.clientserver - DEBUG - Command to send: a
g
o5
i0
e

2025-03-06 17:30:27,119 - py4j.clientserver - DEBUG - Answer received: !yro6
2025-03-06 17:30:27,119 - py4j.clientserver - DEBUG - Command to send: c
o6
_1
e

2025-03-06 17:30:27,121 - py4j.clientserver - DEBUG - Answer received: !ysspark.rdd.compress
2025-03-06 17:30:27,121 - py4j.clientserver - DEBUG - Command to send: c
o6
_2
e

2025-03-06 17:30:27,121 - py4j.clientserver - DEBUG - Answer received: !ysTrue
2025-03-06 17:30:27,121 - py4j.clientserver - DEBUG - Command to send: a
e
o5
e

2025-03-06 17:30:27,122 - py4j.clientserver - DEBUG - Answer received: !yi9
2025-03-06 17:30:27,122 - py4j.clientserver - DEBUG - Command to send: a
g
o5
i1
e

2025-03-06 17:30:27,122 - py4j.clientserver - DEBUG - Answer received: !yro7
2025-03-06 17:30:27,122 - py4j.clientserver - DEBUG - Command to send: c
o7
_1
e

2025-03-06 17:30:27,123 - py4j.clientserver - DEBUG - Answer received: !ysspark.serializer.objectStreamReset
2025-03-06 17:30:27,123 - py4j.clientserver - DEBUG - Command to send: c
o7
_2
e

2025-03-06 17:30:27,124 - py4j.clientserver - DEBUG - Answer received: !ys100
2025-03-06 17:30:27,124 - py4j.clientserver - DEBUG - Command to send: a
e
o5
e

2025-03-06 17:30:27,125 - py4j.clientserver - DEBUG - Answer received: !yi9
2025-03-06 17:30:27,125 - py4j.clientserver - DEBUG - Command to send: a
g
o5
i2
e

2025-03-06 17:30:27,125 - py4j.clientserver - DEBUG - Answer received: !yro8
2025-03-06 17:30:27,125 - py4j.clientserver - DEBUG - Command to send: c
o8
_1
e

2025-03-06 17:30:27,126 - py4j.clientserver - DEBUG - Answer received: !ysspark.hadoop.fs.file.impl
2025-03-06 17:30:27,126 - py4j.clientserver - DEBUG - Command to send: c
o8
_2
e

2025-03-06 17:30:27,126 - py4j.clientserver - DEBUG - Answer received: !ysorg.apache.hadoop.fs.LocalFileSystem
2025-03-06 17:30:27,128 - py4j.clientserver - DEBUG - Command to send: a
e
o5
e

2025-03-06 17:30:27,128 - py4j.clientserver - DEBUG - Answer received: !yi9
2025-03-06 17:30:27,128 - py4j.clientserver - DEBUG - Command to send: a
g
o5
i3
e

2025-03-06 17:30:27,128 - py4j.clientserver - DEBUG - Answer received: !yro9
2025-03-06 17:30:27,128 - py4j.clientserver - DEBUG - Command to send: c
o9
_1
e

2025-03-06 17:30:27,130 - py4j.clientserver - DEBUG - Answer received: !ysspark.master
2025-03-06 17:30:27,130 - py4j.clientserver - DEBUG - Command to send: c
o9
_2
e

2025-03-06 17:30:27,130 - py4j.clientserver - DEBUG - Answer received: !yslocal[*]
2025-03-06 17:30:27,131 - py4j.clientserver - DEBUG - Command to send: a
e
o5
e

2025-03-06 17:30:27,131 - py4j.clientserver - DEBUG - Answer received: !yi9
2025-03-06 17:30:27,131 - py4j.clientserver - DEBUG - Command to send: a
g
o5
i4
e

2025-03-06 17:30:27,132 - py4j.clientserver - DEBUG - Answer received: !yro10
2025-03-06 17:30:27,132 - py4j.clientserver - DEBUG - Command to send: c
o10
_1
e

2025-03-06 17:30:27,132 - py4j.clientserver - DEBUG - Answer received: !ysspark.submit.pyFiles
2025-03-06 17:30:27,133 - py4j.clientserver - DEBUG - Command to send: c
o10
_2
e

2025-03-06 17:30:27,133 - py4j.clientserver - DEBUG - Answer received: !ys
2025-03-06 17:30:27,134 - py4j.clientserver - DEBUG - Command to send: a
e
o5
e

2025-03-06 17:30:27,135 - py4j.clientserver - DEBUG - Answer received: !yi9
2025-03-06 17:30:27,135 - py4j.clientserver - DEBUG - Command to send: a
g
o5
i5
e

2025-03-06 17:30:27,135 - py4j.clientserver - DEBUG - Answer received: !yro11
2025-03-06 17:30:27,135 - py4j.clientserver - DEBUG - Command to send: c
o11
_1
e

2025-03-06 17:30:27,135 - py4j.clientserver - DEBUG - Answer received: !ysspark.submit.deployMode
2025-03-06 17:30:27,135 - py4j.clientserver - DEBUG - Command to send: c
o11
_2
e

2025-03-06 17:30:27,135 - py4j.clientserver - DEBUG - Answer received: !ysclient
2025-03-06 17:30:27,135 - py4j.clientserver - DEBUG - Command to send: a
e
o5
e

2025-03-06 17:30:27,135 - py4j.clientserver - DEBUG - Answer received: !yi9
2025-03-06 17:30:27,135 - py4j.clientserver - DEBUG - Command to send: a
g
o5
i6
e

2025-03-06 17:30:27,135 - py4j.clientserver - DEBUG - Answer received: !yro12
2025-03-06 17:30:27,135 - py4j.clientserver - DEBUG - Command to send: c
o12
_1
e

2025-03-06 17:30:27,135 - py4j.clientserver - DEBUG - Answer received: !ysspark.app.name
2025-03-06 17:30:27,135 - py4j.clientserver - DEBUG - Command to send: c
o12
_2
e

2025-03-06 17:30:27,135 - py4j.clientserver - DEBUG - Answer received: !ysWordProcessing
2025-03-06 17:30:27,140 - py4j.clientserver - DEBUG - Command to send: a
e
o5
e

2025-03-06 17:30:27,140 - py4j.clientserver - DEBUG - Answer received: !yi9
2025-03-06 17:30:27,140 - py4j.clientserver - DEBUG - Command to send: a
g
o5
i7
e

2025-03-06 17:30:27,141 - py4j.clientserver - DEBUG - Answer received: !yro13
2025-03-06 17:30:27,141 - py4j.clientserver - DEBUG - Command to send: c
o13
_1
e

2025-03-06 17:30:27,142 - py4j.clientserver - DEBUG - Answer received: !ysspark.ui.showConsoleProgress
2025-03-06 17:30:27,142 - py4j.clientserver - DEBUG - Command to send: c
o13
_2
e

2025-03-06 17:30:27,142 - py4j.clientserver - DEBUG - Answer received: !ystrue
2025-03-06 17:30:27,142 - py4j.clientserver - DEBUG - Command to send: a
e
o5
e

2025-03-06 17:30:27,143 - py4j.clientserver - DEBUG - Answer received: !yi9
2025-03-06 17:30:27,143 - py4j.clientserver - DEBUG - Command to send: a
g
o5
i8
e

2025-03-06 17:30:27,143 - py4j.clientserver - DEBUG - Answer received: !yro14
2025-03-06 17:30:27,143 - py4j.clientserver - DEBUG - Command to send: c
o14
_1
e

2025-03-06 17:30:27,144 - py4j.clientserver - DEBUG - Answer received: !ysspark.app.submitTime
2025-03-06 17:30:27,144 - py4j.clientserver - DEBUG - Command to send: c
o14
_2
e

2025-03-06 17:30:27,144 - py4j.clientserver - DEBUG - Answer received: !ys1741262426966
2025-03-06 17:30:27,144 - py4j.clientserver - DEBUG - Command to send: a
e
o5
e

2025-03-06 17:30:27,144 - py4j.clientserver - DEBUG - Answer received: !yi9
2025-03-06 17:30:27,144 - py4j.clientserver - DEBUG - Command to send: r
u
JavaSparkContext
rj
e

2025-03-06 17:30:27,158 - py4j.clientserver - DEBUG - Answer received: !ycorg.apache.spark.api.java.JavaSparkContext
2025-03-06 17:30:27,158 - py4j.clientserver - DEBUG - Command to send: i
org.apache.spark.api.java.JavaSparkContext
ro0
e

2025-03-06 17:30:28,049 - py4j.clientserver - DEBUG - Command to send: A
f1e8604e450cd81dcbda5696091d20eaa7b1b076d12fd2229c32ff2bae579c8f

2025-03-06 17:30:28,049 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:28,049 - py4j.clientserver - DEBUG - Command to send: m
d
o1
e

2025-03-06 17:30:28,049 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:28,049 - py4j.clientserver - DEBUG - Command to send: m
d
o2
e

2025-03-06 17:30:28,049 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:28,049 - py4j.clientserver - DEBUG - Command to send: m
d
o3
e

2025-03-06 17:30:28,049 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:28,049 - py4j.clientserver - DEBUG - Command to send: m
d
o4
e

2025-03-06 17:30:28,055 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:28,055 - py4j.clientserver - DEBUG - Command to send: m
d
o5
e

2025-03-06 17:30:28,055 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:28,813 - py4j.clientserver - DEBUG - Answer received: !yro15
2025-03-06 17:30:28,813 - py4j.clientserver - DEBUG - Command to send: c
o15
sc
e

2025-03-06 17:30:28,813 - py4j.clientserver - DEBUG - Answer received: !yro16
2025-03-06 17:30:28,813 - py4j.clientserver - DEBUG - Command to send: c
o16
conf
e

2025-03-06 17:30:28,820 - py4j.clientserver - DEBUG - Answer received: !yro17
2025-03-06 17:30:28,832 - py4j.clientserver - DEBUG - Command to send: r
u
PythonAccumulatorV2
rj
e

2025-03-06 17:30:28,834 - py4j.clientserver - DEBUG - Answer received: !ycorg.apache.spark.api.python.PythonAccumulatorV2
2025-03-06 17:30:28,835 - py4j.clientserver - DEBUG - Command to send: i
org.apache.spark.api.python.PythonAccumulatorV2
s127.0.0.1
i57749
sf1e8604e450cd81dcbda5696091d20eaa7b1b076d12fd2229c32ff2bae579c8f
e

2025-03-06 17:30:28,836 - py4j.clientserver - DEBUG - Answer received: !yro18
2025-03-06 17:30:28,837 - py4j.clientserver - DEBUG - Command to send: c
o15
sc
e

2025-03-06 17:30:28,837 - py4j.clientserver - DEBUG - Answer received: !yro19
2025-03-06 17:30:28,837 - py4j.clientserver - DEBUG - Command to send: c
o19
register
ro18
e

2025-03-06 17:30:28,841 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:28,841 - py4j.clientserver - DEBUG - Command to send: r
u
PythonUtils
rj
e

2025-03-06 17:30:28,843 - py4j.clientserver - DEBUG - Answer received: !ycorg.apache.spark.api.python.PythonUtils
2025-03-06 17:30:28,844 - py4j.clientserver - DEBUG - Command to send: r
m
org.apache.spark.api.python.PythonUtils
isEncryptionEnabled
e

2025-03-06 17:30:28,845 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:28,845 - py4j.clientserver - DEBUG - Command to send: c
z:org.apache.spark.api.python.PythonUtils
isEncryptionEnabled
ro15
e

2025-03-06 17:30:28,847 - py4j.clientserver - DEBUG - Answer received: !ybfalse
2025-03-06 17:30:28,847 - py4j.clientserver - DEBUG - Command to send: r
u
PythonUtils
rj
e

2025-03-06 17:30:28,850 - py4j.clientserver - DEBUG - Answer received: !ycorg.apache.spark.api.python.PythonUtils
2025-03-06 17:30:28,850 - py4j.clientserver - DEBUG - Command to send: r
m
org.apache.spark.api.python.PythonUtils
getPythonAuthSocketTimeout
e

2025-03-06 17:30:28,851 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:28,851 - py4j.clientserver - DEBUG - Command to send: c
z:org.apache.spark.api.python.PythonUtils
getPythonAuthSocketTimeout
ro15
e

2025-03-06 17:30:28,852 - py4j.clientserver - DEBUG - Answer received: !yL15
2025-03-06 17:30:28,852 - py4j.clientserver - DEBUG - Command to send: r
u
PythonUtils
rj
e

2025-03-06 17:30:28,853 - py4j.clientserver - DEBUG - Answer received: !ycorg.apache.spark.api.python.PythonUtils
2025-03-06 17:30:28,853 - py4j.clientserver - DEBUG - Command to send: r
m
org.apache.spark.api.python.PythonUtils
getSparkBufferSize
e

2025-03-06 17:30:28,854 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:28,855 - py4j.clientserver - DEBUG - Command to send: c
z:org.apache.spark.api.python.PythonUtils
getSparkBufferSize
ro15
e

2025-03-06 17:30:28,856 - py4j.clientserver - DEBUG - Answer received: !yi65536
2025-03-06 17:30:28,856 - py4j.clientserver - DEBUG - Command to send: r
u
org
rj
e

2025-03-06 17:30:28,858 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:28,859 - py4j.clientserver - DEBUG - Command to send: r
u
org.apache
rj
e

2025-03-06 17:30:28,860 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:28,860 - py4j.clientserver - DEBUG - Command to send: r
u
org.apache.spark
rj
e

2025-03-06 17:30:28,862 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:28,862 - py4j.clientserver - DEBUG - Command to send: r
u
org.apache.spark.SparkFiles
rj
e

2025-03-06 17:30:28,864 - py4j.clientserver - DEBUG - Answer received: !ycorg.apache.spark.SparkFiles
2025-03-06 17:30:28,864 - py4j.clientserver - DEBUG - Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

2025-03-06 17:30:28,864 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:28,865 - py4j.clientserver - DEBUG - Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

2025-03-06 17:30:28,867 - py4j.clientserver - DEBUG - Answer received: !ysC:\\Users\\Udith\\AppData\\Local\\Temp\\spark-a47076ff-56fa-40d6-b6a7-023e789ffade\\userFiles-49c4ffcf-2990-42ed-bbc0-478533067a6a
2025-03-06 17:30:28,867 - py4j.clientserver - DEBUG - Command to send: c
o17
get
sspark.submit.pyFiles
s
e

2025-03-06 17:30:28,869 - py4j.clientserver - DEBUG - Answer received: !ys
2025-03-06 17:30:28,869 - py4j.clientserver - DEBUG - Command to send: r
u
org
rj
e

2025-03-06 17:30:28,873 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:28,873 - py4j.clientserver - DEBUG - Command to send: r
u
org.apache
rj
e

2025-03-06 17:30:28,874 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:28,874 - py4j.clientserver - DEBUG - Command to send: r
u
org.apache.spark
rj
e

2025-03-06 17:30:28,875 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:28,876 - py4j.clientserver - DEBUG - Command to send: r
u
org.apache.spark.util
rj
e

2025-03-06 17:30:28,877 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:28,878 - py4j.clientserver - DEBUG - Command to send: r
u
org.apache.spark.util.Utils
rj
e

2025-03-06 17:30:28,880 - py4j.clientserver - DEBUG - Answer received: !ycorg.apache.spark.util.Utils
2025-03-06 17:30:28,880 - py4j.clientserver - DEBUG - Command to send: r
m
org.apache.spark.util.Utils
getLocalDir
e

2025-03-06 17:30:28,884 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:28,884 - py4j.clientserver - DEBUG - Command to send: c
o15
sc
e

2025-03-06 17:30:28,884 - py4j.clientserver - DEBUG - Answer received: !yro20
2025-03-06 17:30:28,884 - py4j.clientserver - DEBUG - Command to send: c
o20
conf
e

2025-03-06 17:30:28,887 - py4j.clientserver - DEBUG - Answer received: !yro21
2025-03-06 17:30:28,887 - py4j.clientserver - DEBUG - Command to send: c
z:org.apache.spark.util.Utils
getLocalDir
ro21
e

2025-03-06 17:30:28,888 - py4j.clientserver - DEBUG - Answer received: !ysC:\\Users\\Udith\\AppData\\Local\\Temp\\spark-a47076ff-56fa-40d6-b6a7-023e789ffade
2025-03-06 17:30:28,888 - py4j.clientserver - DEBUG - Command to send: r
u
org
rj
e

2025-03-06 17:30:28,890 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:28,890 - py4j.clientserver - DEBUG - Command to send: r
u
org.apache
rj
e

2025-03-06 17:30:28,891 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:28,891 - py4j.clientserver - DEBUG - Command to send: r
u
org.apache.spark
rj
e

2025-03-06 17:30:28,891 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:28,891 - py4j.clientserver - DEBUG - Command to send: r
u
org.apache.spark.util
rj
e

2025-03-06 17:30:28,891 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:28,891 - py4j.clientserver - DEBUG - Command to send: r
u
org.apache.spark.util.Utils
rj
e

2025-03-06 17:30:28,891 - py4j.clientserver - DEBUG - Answer received: !ycorg.apache.spark.util.Utils
2025-03-06 17:30:28,891 - py4j.clientserver - DEBUG - Command to send: r
m
org.apache.spark.util.Utils
createTempDir
e

2025-03-06 17:30:28,891 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:28,891 - py4j.clientserver - DEBUG - Command to send: c
z:org.apache.spark.util.Utils
createTempDir
sC:\\Users\\Udith\\AppData\\Local\\Temp\\spark-a47076ff-56fa-40d6-b6a7-023e789ffade
spyspark
e

2025-03-06 17:30:28,898 - py4j.clientserver - DEBUG - Answer received: !yro22
2025-03-06 17:30:28,899 - py4j.clientserver - DEBUG - Command to send: c
o22
getAbsolutePath
e

2025-03-06 17:30:28,900 - py4j.clientserver - DEBUG - Answer received: !ysC:\\Users\\Udith\\AppData\\Local\\Temp\\spark-a47076ff-56fa-40d6-b6a7-023e789ffade\\pyspark-a419153f-dda9-446a-a0b1-cf8a6613cd90
2025-03-06 17:30:28,900 - py4j.clientserver - DEBUG - Command to send: c
o17
get
sspark.python.profile
sfalse
e

2025-03-06 17:30:28,901 - py4j.clientserver - DEBUG - Answer received: !ysfalse
2025-03-06 17:30:28,902 - py4j.clientserver - DEBUG - Command to send: c
o17
get
sspark.python.profile.memory
sfalse
e

2025-03-06 17:30:28,902 - py4j.clientserver - DEBUG - Answer received: !ysfalse
2025-03-06 17:30:28,902 - py4j.clientserver - DEBUG - Command to send: r
u
SparkSession
rj
e

2025-03-06 17:30:28,933 - py4j.clientserver - DEBUG - Answer received: !ycorg.apache.spark.sql.SparkSession
2025-03-06 17:30:28,933 - py4j.clientserver - DEBUG - Command to send: r
m
org.apache.spark.sql.SparkSession
getDefaultSession
e

2025-03-06 17:30:28,968 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:28,972 - py4j.clientserver - DEBUG - Command to send: c
z:org.apache.spark.sql.SparkSession
getDefaultSession
e

2025-03-06 17:30:28,974 - py4j.clientserver - DEBUG - Answer received: !yro23
2025-03-06 17:30:28,974 - py4j.clientserver - DEBUG - Command to send: c
o23
isDefined
e

2025-03-06 17:30:28,974 - py4j.clientserver - DEBUG - Answer received: !ybfalse
2025-03-06 17:30:28,974 - py4j.clientserver - DEBUG - Command to send: r
u
SparkSession
rj
e

2025-03-06 17:30:28,976 - py4j.clientserver - DEBUG - Answer received: !ycorg.apache.spark.sql.SparkSession
2025-03-06 17:30:28,976 - py4j.clientserver - DEBUG - Command to send: c
o15
sc
e

2025-03-06 17:30:28,976 - py4j.clientserver - DEBUG - Answer received: !yro24
2025-03-06 17:30:28,978 - py4j.clientserver - DEBUG - Command to send: i
java.util.HashMap
e

2025-03-06 17:30:28,978 - py4j.clientserver - DEBUG - Answer received: !yao25
2025-03-06 17:30:28,978 - py4j.clientserver - DEBUG - Command to send: c
o25
put
sspark.app.name
sWordProcessing
e

2025-03-06 17:30:28,979 - py4j.clientserver - DEBUG - Answer received: !yn
2025-03-06 17:30:28,979 - py4j.clientserver - DEBUG - Command to send: c
o25
put
sspark.hadoop.fs.file.impl
sorg.apache.hadoop.fs.LocalFileSystem
e

2025-03-06 17:30:28,980 - py4j.clientserver - DEBUG - Answer received: !yn
2025-03-06 17:30:28,980 - py4j.clientserver - DEBUG - Command to send: i
org.apache.spark.sql.SparkSession
ro24
ro25
e

2025-03-06 17:30:29,046 - py4j.clientserver - DEBUG - Answer received: !yro26
2025-03-06 17:30:29,046 - py4j.clientserver - DEBUG - Command to send: r
u
SparkSession
rj
e

2025-03-06 17:30:29,046 - py4j.clientserver - DEBUG - Answer received: !ycorg.apache.spark.sql.SparkSession
2025-03-06 17:30:29,046 - py4j.clientserver - DEBUG - Command to send: r
m
org.apache.spark.sql.SparkSession
setDefaultSession
e

2025-03-06 17:30:29,046 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:29,046 - py4j.clientserver - DEBUG - Command to send: c
z:org.apache.spark.sql.SparkSession
setDefaultSession
ro26
e

2025-03-06 17:30:29,046 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:29,055 - py4j.clientserver - DEBUG - Command to send: r
u
SparkSession
rj
e

2025-03-06 17:30:29,057 - py4j.clientserver - DEBUG - Answer received: !ycorg.apache.spark.sql.SparkSession
2025-03-06 17:30:29,058 - py4j.clientserver - DEBUG - Command to send: m
d
o6
e

2025-03-06 17:30:29,058 - py4j.clientserver - DEBUG - Command to send: r
m
org.apache.spark.sql.SparkSession
setActiveSession
e

2025-03-06 17:30:29,058 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:29,059 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:29,059 - py4j.clientserver - DEBUG - Command to send: m
d
o7
e

2025-03-06 17:30:29,059 - py4j.clientserver - DEBUG - Command to send: c
z:org.apache.spark.sql.SparkSession
setActiveSession
ro26
e

2025-03-06 17:30:29,059 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:29,059 - py4j.clientserver - DEBUG - Command to send: m
d
o8
e

2025-03-06 17:30:29,059 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:29,059 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:29,059 - __main__ - INFO - Running process_data command
2025-03-06 17:30:29,059 - py4j.clientserver - DEBUG - Command to send: m
d
o9
e

2025-03-06 17:30:29,059 - __main__ - INFO - Loading configuration from code/config/cfg.yaml
2025-03-06 17:30:29,059 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:29,059 - py4j.clientserver - DEBUG - Command to send: m
d
o10
e

2025-03-06 17:30:29,059 - process_data - INFO - Processing selected words: ['president', 'the', 'Asia']
2025-03-06 17:30:29,059 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:29,059 - py4j.clientserver - DEBUG - Command to send: c
o26
read
e

2025-03-06 17:30:29,063 - py4j.clientserver - DEBUG - Command to send: m
d
o11
e

2025-03-06 17:30:29,064 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:29,064 - py4j.clientserver - DEBUG - Command to send: m
d
o12
e

2025-03-06 17:30:29,064 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:29,065 - py4j.clientserver - DEBUG - Command to send: m
d
o13
e

2025-03-06 17:30:29,065 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:29,065 - py4j.clientserver - DEBUG - Command to send: m
d
o14
e

2025-03-06 17:30:29,066 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:29,066 - py4j.clientserver - DEBUG - Command to send: m
d
o25
e

2025-03-06 17:30:29,066 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:29,939 - py4j.clientserver - DEBUG - Answer received: !yro27
2025-03-06 17:30:29,939 - py4j.clientserver - DEBUG - Command to send: r
u
PythonUtils
rj
e

2025-03-06 17:30:29,939 - py4j.clientserver - DEBUG - Answer received: !ycorg.apache.spark.api.python.PythonUtils
2025-03-06 17:30:29,939 - py4j.clientserver - DEBUG - Command to send: r
m
org.apache.spark.api.python.PythonUtils
toSeq
e

2025-03-06 17:30:29,939 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:29,939 - py4j.clientserver - DEBUG - Command to send: i
java.util.ArrayList
e

2025-03-06 17:30:29,939 - py4j.clientserver - DEBUG - Answer received: !ylo28
2025-03-06 17:30:29,939 - py4j.clientserver - DEBUG - Command to send: c
o28
add
ssh0416/ag_news.jsonl
e

2025-03-06 17:30:29,939 - py4j.clientserver - DEBUG - Answer received: !ybtrue
2025-03-06 17:30:29,939 - py4j.clientserver - DEBUG - Command to send: c
z:org.apache.spark.api.python.PythonUtils
toSeq
ro28
e

2025-03-06 17:30:29,939 - py4j.clientserver - DEBUG - Answer received: !yro29
2025-03-06 17:30:29,939 - py4j.clientserver - DEBUG - Command to send: c
o27
json
ro29
e

2025-03-06 17:30:30,068 - py4j.clientserver - DEBUG - Command to send: m
d
o28
e

2025-03-06 17:30:30,068 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:33,683 - py4j.clientserver - DEBUG - Answer received: !yro30
2025-03-06 17:30:33,683 - py4j.clientserver - DEBUG - Command to send: c
o30
schema
e

2025-03-06 17:30:33,711 - py4j.clientserver - DEBUG - Answer received: !yro31
2025-03-06 17:30:33,711 - py4j.clientserver - DEBUG - Command to send: c
o31
json
e

2025-03-06 17:30:33,738 - py4j.clientserver - DEBUG - Answer received: !ys{"type":"struct","fields":[{"name":"description","type":"string","nullable":true,"metadata":{}},{"name":"label","type":"long","nullable":true,"metadata":{}},{"name":"title","type":"string","nullable":true,"metadata":{}}]}
2025-03-06 17:30:33,738 - py4j.clientserver - DEBUG - Command to send: r
u
functions
rj
e

2025-03-06 17:30:33,745 - py4j.clientserver - DEBUG - Answer received: !ycorg.apache.spark.sql.functions
2025-03-06 17:30:33,745 - py4j.clientserver - DEBUG - Command to send: r
m
org.apache.spark.sql.functions
col
e

2025-03-06 17:30:33,755 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:33,756 - py4j.clientserver - DEBUG - Command to send: c
z:org.apache.spark.sql.functions
col
sdescription
e

2025-03-06 17:30:33,786 - py4j.clientserver - DEBUG - Answer received: !yro32
2025-03-06 17:30:33,787 - py4j.clientserver - DEBUG - Command to send: c
o32
contains
spresident
e

2025-03-06 17:30:33,789 - py4j.clientserver - DEBUG - Answer received: !yro33
2025-03-06 17:30:33,789 - py4j.clientserver - DEBUG - Command to send: c
o30
filter
ro33
e

2025-03-06 17:30:33,800 - py4j.clientserver - DEBUG - Answer received: !yro34
2025-03-06 17:30:33,800 - py4j.clientserver - DEBUG - Command to send: c
o34
count
e

2025-03-06 17:30:34,819 - py4j.clientserver - DEBUG - Answer received: !yL2888
2025-03-06 17:30:34,819 - process_data - DEBUG - Word: president, Count: 2888
2025-03-06 17:30:34,821 - py4j.clientserver - DEBUG - Command to send: r
u
functions
rj
e

2025-03-06 17:30:34,823 - py4j.clientserver - DEBUG - Answer received: !ycorg.apache.spark.sql.functions
2025-03-06 17:30:34,823 - py4j.clientserver - DEBUG - Command to send: r
m
org.apache.spark.sql.functions
col
e

2025-03-06 17:30:34,823 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:34,825 - py4j.clientserver - DEBUG - Command to send: c
z:org.apache.spark.sql.functions
col
sdescription
e

2025-03-06 17:30:34,825 - py4j.clientserver - DEBUG - Answer received: !yro35
2025-03-06 17:30:34,826 - py4j.clientserver - DEBUG - Command to send: c
o35
contains
sthe
e

2025-03-06 17:30:34,826 - py4j.clientserver - DEBUG - Answer received: !yro36
2025-03-06 17:30:34,826 - py4j.clientserver - DEBUG - Command to send: c
o30
filter
ro36
e

2025-03-06 17:30:34,832 - py4j.clientserver - DEBUG - Answer received: !yro37
2025-03-06 17:30:34,833 - py4j.clientserver - DEBUG - Command to send: c
o37
count
e

2025-03-06 17:30:35,137 - py4j.clientserver - DEBUG - Answer received: !yL98188
2025-03-06 17:30:35,137 - process_data - DEBUG - Word: the, Count: 98188
2025-03-06 17:30:35,137 - py4j.clientserver - DEBUG - Command to send: r
u
functions
rj
e

2025-03-06 17:30:35,140 - py4j.clientserver - DEBUG - Answer received: !ycorg.apache.spark.sql.functions
2025-03-06 17:30:35,140 - py4j.clientserver - DEBUG - Command to send: r
m
org.apache.spark.sql.functions
col
e

2025-03-06 17:30:35,140 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:35,140 - py4j.clientserver - DEBUG - Command to send: c
z:org.apache.spark.sql.functions
col
sdescription
e

2025-03-06 17:30:35,145 - py4j.clientserver - DEBUG - Answer received: !yro38
2025-03-06 17:30:35,145 - py4j.clientserver - DEBUG - Command to send: c
o38
contains
sAsia
e

2025-03-06 17:30:35,146 - py4j.clientserver - DEBUG - Answer received: !yro39
2025-03-06 17:30:35,147 - py4j.clientserver - DEBUG - Command to send: c
o30
filter
ro39
e

2025-03-06 17:30:35,153 - py4j.clientserver - DEBUG - Answer received: !yro40
2025-03-06 17:30:35,155 - py4j.clientserver - DEBUG - Command to send: c
o40
count
e

2025-03-06 17:30:35,449 - py4j.clientserver - DEBUG - Answer received: !yL1032
2025-03-06 17:30:35,449 - process_data - DEBUG - Word: Asia, Count: 1032
2025-03-06 17:30:35,451 - py4j.clientserver - DEBUG - Command to send: r
u
SparkSession
rj
e

2025-03-06 17:30:35,454 - py4j.clientserver - DEBUG - Answer received: !ycorg.apache.spark.sql.SparkSession
2025-03-06 17:30:35,454 - py4j.clientserver - DEBUG - Command to send: r
m
org.apache.spark.sql.SparkSession
setActiveSession
e

2025-03-06 17:30:35,454 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:35,454 - py4j.clientserver - DEBUG - Command to send: c
z:org.apache.spark.sql.SparkSession
setActiveSession
ro26
e

2025-03-06 17:30:35,456 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:35,457 - py4j.clientserver - DEBUG - Command to send: c
o26
sessionState
e

2025-03-06 17:30:35,458 - py4j.clientserver - DEBUG - Answer received: !yro41
2025-03-06 17:30:35,458 - py4j.clientserver - DEBUG - Command to send: c
o41
conf
e

2025-03-06 17:30:35,459 - py4j.clientserver - DEBUG - Answer received: !yro42
2025-03-06 17:30:35,460 - py4j.clientserver - DEBUG - Command to send: c
o42
inferDictAsStruct
e

2025-03-06 17:30:35,463 - py4j.clientserver - DEBUG - Answer received: !ybfalse
2025-03-06 17:30:35,463 - py4j.clientserver - DEBUG - Command to send: c
o26
sessionState
e

2025-03-06 17:30:35,464 - py4j.clientserver - DEBUG - Answer received: !yro43
2025-03-06 17:30:35,464 - py4j.clientserver - DEBUG - Command to send: c
o43
conf
e

2025-03-06 17:30:35,466 - py4j.clientserver - DEBUG - Answer received: !yro44
2025-03-06 17:30:35,466 - py4j.clientserver - DEBUG - Command to send: c
o44
legacyInferArrayTypeFromFirstElement
e

2025-03-06 17:30:35,468 - py4j.clientserver - DEBUG - Answer received: !ybfalse
2025-03-06 17:30:35,468 - py4j.clientserver - DEBUG - Command to send: r
u
PythonSQLUtils
rj
e

2025-03-06 17:30:35,472 - py4j.clientserver - DEBUG - Answer received: !ycorg.apache.spark.sql.api.python.PythonSQLUtils
2025-03-06 17:30:35,473 - py4j.clientserver - DEBUG - Command to send: r
m
org.apache.spark.sql.api.python.PythonSQLUtils
isTimestampNTZPreferred
e

2025-03-06 17:30:35,476 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:35,476 - py4j.clientserver - DEBUG - Command to send: c
z:org.apache.spark.sql.api.python.PythonSQLUtils
isTimestampNTZPreferred
e

2025-03-06 17:30:35,489 - py4j.clientserver - DEBUG - Answer received: !ybfalse
2025-03-06 17:30:35,489 - py4j.clientserver - DEBUG - Command to send: c
o15
sc
e

2025-03-06 17:30:35,490 - py4j.clientserver - DEBUG - Answer received: !yro45
2025-03-06 17:30:35,491 - py4j.clientserver - DEBUG - Command to send: c
o45
defaultParallelism
e

2025-03-06 17:30:35,491 - py4j.clientserver - DEBUG - Answer received: !yi16
2025-03-06 17:30:35,493 - py4j.clientserver - DEBUG - Command to send: r
u
PythonRDD
rj
e

2025-03-06 17:30:35,496 - py4j.clientserver - DEBUG - Answer received: !ycorg.apache.spark.api.python.PythonRDD
2025-03-06 17:30:35,496 - py4j.clientserver - DEBUG - Command to send: r
m
org.apache.spark.api.python.PythonRDD
readRDDFromFile
e

2025-03-06 17:30:35,498 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:35,500 - py4j.clientserver - DEBUG - Command to send: c
z:org.apache.spark.api.python.PythonRDD
readRDDFromFile
ro15
sC:\\Users\\Udith\\AppData\\Local\\Temp\\spark-a47076ff-56fa-40d6-b6a7-023e789ffade\\pyspark-a419153f-dda9-446a-a0b1-cf8a6613cd90\\tmpfy2jx6mz
i16
e

2025-03-06 17:30:35,514 - py4j.clientserver - DEBUG - Answer received: !yro46
2025-03-06 17:30:35,516 - py4j.clientserver - DEBUG - Command to send: c
o46
id
e

2025-03-06 17:30:35,523 - py4j.clientserver - DEBUG - Answer received: !yi25
2025-03-06 17:30:35,524 - py4j.clientserver - DEBUG - Command to send: r
u
SerDeUtil
rj
e

2025-03-06 17:30:35,525 - py4j.clientserver - DEBUG - Answer received: !ycorg.apache.spark.api.python.SerDeUtil
2025-03-06 17:30:35,526 - py4j.clientserver - DEBUG - Command to send: r
m
org.apache.spark.api.python.SerDeUtil
toJavaArray
e

2025-03-06 17:30:35,527 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:35,527 - py4j.clientserver - DEBUG - Command to send: c
o46
rdd
e

2025-03-06 17:30:35,528 - py4j.clientserver - DEBUG - Answer received: !yro47
2025-03-06 17:30:35,528 - py4j.clientserver - DEBUG - Command to send: c
o47
isBarrier
e

2025-03-06 17:30:35,531 - py4j.clientserver - DEBUG - Answer received: !ybfalse
2025-03-06 17:30:35,531 - py4j.clientserver - DEBUG - Command to send: r
u
SerDeUtil
rj
e

2025-03-06 17:30:35,533 - py4j.clientserver - DEBUG - Answer received: !ycorg.apache.spark.api.python.SerDeUtil
2025-03-06 17:30:35,533 - py4j.clientserver - DEBUG - Command to send: r
m
org.apache.spark.api.python.SerDeUtil
pythonToJava
e

2025-03-06 17:30:35,534 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:35,535 - py4j.clientserver - DEBUG - Command to send: r
u
PythonUtils
rj
e

2025-03-06 17:30:35,537 - py4j.clientserver - DEBUG - Answer received: !ycorg.apache.spark.api.python.PythonUtils
2025-03-06 17:30:35,537 - py4j.clientserver - DEBUG - Command to send: r
m
org.apache.spark.api.python.PythonUtils
getBroadcastThreshold
e

2025-03-06 17:30:35,537 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:35,538 - py4j.clientserver - DEBUG - Command to send: c
z:org.apache.spark.api.python.PythonUtils
getBroadcastThreshold
ro15
e

2025-03-06 17:30:35,538 - py4j.clientserver - DEBUG - Answer received: !yL1048576
2025-03-06 17:30:35,539 - py4j.clientserver - DEBUG - Command to send: r
u
SimplePythonFunction
rj
e

2025-03-06 17:30:35,542 - py4j.clientserver - DEBUG - Answer received: !ycorg.apache.spark.api.python.SimplePythonFunction
2025-03-06 17:30:35,543 - py4j.clientserver - DEBUG - Command to send: i
java.util.HashMap
e

2025-03-06 17:30:35,543 - py4j.clientserver - DEBUG - Answer received: !yao48
2025-03-06 17:30:35,543 - py4j.clientserver - DEBUG - Command to send: c
o48
put
sPYTHONHASHSEED
s0
e

2025-03-06 17:30:35,543 - py4j.clientserver - DEBUG - Answer received: !yn
2025-03-06 17:30:35,543 - py4j.clientserver - DEBUG - Command to send: i
java.util.ArrayList
e

2025-03-06 17:30:35,543 - py4j.clientserver - DEBUG - Answer received: !ylo49
2025-03-06 17:30:35,543 - py4j.clientserver - DEBUG - Command to send: i
java.util.ArrayList
e

2025-03-06 17:30:35,543 - py4j.clientserver - DEBUG - Answer received: !ylo50
2025-03-06 17:30:35,543 - py4j.clientserver - DEBUG - Command to send: i
org.apache.spark.api.python.SimplePythonFunction
jgAWV3AQAAAAAAAAojB9weXNwYXJrLmNsb3VkcGlja2xlLmNsb3VkcGlja2xllIwOX21ha2VfZnVuY3Rpb26Uk5QoaACMDV9idWlsdGluX3R5cGWUk5SMCENvZGVUeXBllIWUUpQoSwJLAEsASwJLBUsTQz6VAZcAdAEAAAAAAAAAAAAAdAMAAAAAAAAAAAAAiQKmAQAAqwEAAAAAAAAAAHwBpgIAAKsCAAAAAAAAAABTAJROhZSMA21hcJSMFWZhaWxfb25fc3RvcGl0ZXJhdGlvbpSGlIwBX5SMCGl0ZXJhdG9ylIaUjD9DOlxVc2Vyc1xVZGl0aFwuY29uZGFcZW52c1x1emFcTGliXHNpdGUtcGFja2FnZXNccHlzcGFya1xyZGQucHmUjARmdW5jlIwVUkRELm1hcC48bG9jYWxzPi5mdW5jlE3xAkMc+IAA3RMW1RcsqFHRFy/UFy+wGNETOtQTOtAMOpRDAJSMAWaUhZQpdJRSlH2UKIwLX19wYWNrYWdlX1+UjAdweXNwYXJrlIwIX19uYW1lX1+UjAtweXNwYXJrLnJkZJSMCF9fZmlsZV9flGgQdU5OaACMEF9tYWtlX2VtcHR5X2NlbGyUk5QpUpSFlHSUUpSMJHB5c3BhcmsuY2xvdWRwaWNrbGUuY2xvdWRwaWNrbGVfZmFzdJSMEl9mdW5jdGlvbl9zZXRzdGF0ZZSTlGgkfZR9lChoHGgRjAxfX3F1YWxuYW1lX1+UaBKMD19fYW5ub3RhdGlvbnNfX5R9lChoDYwIYnVpbHRpbnOUjANpbnSUk5RoDowJX29wZXJhdG9ylIwHZ2V0aXRlbZSTlIwGdHlwaW5nlIwISXRlcmFibGWUk5SMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlGgAjAlzdWJpbXBvcnSUk5RoHYWUUpSMAVSUhpRSlIaUUpSMBnJldHVybpRoMmg1aDhoPIwBVZSGlFKUhpRSlHWMDl9fa3dkZWZhdWx0c19flE6MDF9fZGVmYXVsdHNfX5ROjApfX21vZHVsZV9flGgdjAdfX2RvY19flE6MC19fY2xvc3VyZV9flGgAjApfbWFrZV9jZWxslJOUaAIoaAcoSwFLAEsASwFLAUsTQwaXAHwAUwCUaAkpjAF4lIWUaBCMCDxsYW1iZGE+lIwiUkRELl9yZXNlcmlhbGl6ZS48bG9jYWxzPi48bGFtYmRhPpRNJQVDBoAAoGGAAJRoFCkpdJRSlGgZTk5OdJRSlGgnaFh9lH2UKGgcaFJoKmhTaCt9lGhITmhJTmhKaB1oS05oTE6MF19jbG91ZHBpY2tsZV9zdWJtb2R1bGVzlF2UjAtfX2dsb2JhbHNfX5R9lHWGlIZSMIWUUpSFlGhcXZRoXn2UaAuMDHB5c3BhcmsudXRpbJRoC5OUc3WGlIZSME6ME3B5c3Bhcmsuc2VyaWFsaXplcnOUjBFCYXRjaGVkU2VyaWFsaXplcpSTlCmBlH2UKIwKc2VyaWFsaXplcpRoaYwVQ2xvdWRQaWNrbGVTZXJpYWxpemVylJOUKYGUjAliYXRjaFNpemWUSwF1YmhpjBVBdXRvQmF0Y2hlZFNlcmlhbGl6ZXKUk5QpgZR9lChobmhwKYGUaHJLAIwIYmVzdFNpemWUSgAAAQB1YnSULg==
ro48
ro49
spython
s3.11
ro50
ro18
e

2025-03-06 17:30:35,559 - py4j.clientserver - DEBUG - Answer received: !yro51
2025-03-06 17:30:35,560 - py4j.clientserver - DEBUG - Command to send: r
u
PythonRDD
rj
e

2025-03-06 17:30:35,561 - py4j.clientserver - DEBUG - Answer received: !ycorg.apache.spark.api.python.PythonRDD
2025-03-06 17:30:35,562 - py4j.clientserver - DEBUG - Command to send: c
o46
rdd
e

2025-03-06 17:30:35,563 - py4j.clientserver - DEBUG - Answer received: !yro52
2025-03-06 17:30:35,563 - py4j.clientserver - DEBUG - Command to send: i
org.apache.spark.api.python.PythonRDD
ro52
ro51
bTrue
bFalse
e

2025-03-06 17:30:35,566 - py4j.clientserver - DEBUG - Answer received: !yro53
2025-03-06 17:30:35,567 - py4j.clientserver - DEBUG - Command to send: c
o53
asJavaRDD
e

2025-03-06 17:30:35,568 - py4j.clientserver - DEBUG - Answer received: !yro54
2025-03-06 17:30:35,568 - py4j.clientserver - DEBUG - Command to send: c
z:org.apache.spark.api.python.SerDeUtil
pythonToJava
ro54
bTrue
e

2025-03-06 17:30:35,583 - py4j.clientserver - DEBUG - Answer received: !yro55
2025-03-06 17:30:35,583 - py4j.clientserver - DEBUG - Command to send: c
z:org.apache.spark.api.python.SerDeUtil
toJavaArray
ro55
e

2025-03-06 17:30:35,585 - py4j.clientserver - DEBUG - Answer received: !yro56
2025-03-06 17:30:35,585 - py4j.clientserver - DEBUG - Command to send: c
o56
rdd
e

2025-03-06 17:30:35,585 - py4j.clientserver - DEBUG - Answer received: !yro57
2025-03-06 17:30:35,589 - py4j.clientserver - DEBUG - Command to send: c
o26
applySchemaToPythonRDD
ro57
s{"fields":[{"metadata":{},"name":"word","nullable":true,"type":"string"},{"metadata":{},"name":"count","nullable":true,"type":"long"}],"type":"struct"}
e

2025-03-06 17:30:35,606 - py4j.clientserver - DEBUG - Answer received: !yro58
2025-03-06 17:30:35,611 - py4j.clientserver - DEBUG - Command to send: c
o58
write
e

2025-03-06 17:30:35,612 - py4j.clientserver - DEBUG - Answer received: !yro59
2025-03-06 17:30:35,612 - py4j.clientserver - DEBUG - Command to send: c
o59
mode
soverwrite
e

2025-03-06 17:30:35,621 - py4j.clientserver - DEBUG - Answer received: !yro60
2025-03-06 17:30:35,621 - py4j.clientserver - DEBUG - Command to send: c
o60
parquet
sztmp\\data\\word_count_20250306.parquet
e

2025-03-06 17:30:36,071 - py4j.clientserver - DEBUG - Command to send: m
d
o48
e

2025-03-06 17:30:36,071 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:36,071 - py4j.clientserver - DEBUG - Command to send: m
d
o49
e

2025-03-06 17:30:36,071 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:36,071 - py4j.clientserver - DEBUG - Command to send: m
d
o50
e

2025-03-06 17:30:36,071 - py4j.clientserver - DEBUG - Answer received: !yv
2025-03-06 17:30:49,163 - py4j.clientserver - DEBUG - Answer received: !xro61
2025-03-06 17:30:49,164 - py4j.clientserver - DEBUG - Command to send: r
u
py4j
rj
e

2025-03-06 17:30:49,166 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,166 - py4j.clientserver - DEBUG - Command to send: r
u
py4j.reflection
rj
e

2025-03-06 17:30:49,166 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,166 - py4j.clientserver - DEBUG - Command to send: r
u
py4j.reflection.TypeUtil
rj
e

2025-03-06 17:30:49,166 - py4j.clientserver - DEBUG - Answer received: !ycpy4j.reflection.TypeUtil
2025-03-06 17:30:49,166 - py4j.clientserver - DEBUG - Command to send: r
m
py4j.reflection.TypeUtil
isInstanceOf
e

2025-03-06 17:30:49,166 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:49,166 - py4j.clientserver - DEBUG - Command to send: c
z:py4j.reflection.TypeUtil
isInstanceOf
sorg.apache.spark.sql.catalyst.parser.ParseException
ro61
e

2025-03-06 17:30:49,170 - py4j.clientserver - DEBUG - Answer received: !ybfalse
2025-03-06 17:30:49,170 - py4j.clientserver - DEBUG - Command to send: r
u
py4j
rj
e

2025-03-06 17:30:49,172 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,172 - py4j.clientserver - DEBUG - Command to send: r
u
py4j.reflection
rj
e

2025-03-06 17:30:49,174 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,174 - py4j.clientserver - DEBUG - Command to send: r
u
py4j.reflection.TypeUtil
rj
e

2025-03-06 17:30:49,174 - py4j.clientserver - DEBUG - Answer received: !ycpy4j.reflection.TypeUtil
2025-03-06 17:30:49,175 - py4j.clientserver - DEBUG - Command to send: r
m
py4j.reflection.TypeUtil
isInstanceOf
e

2025-03-06 17:30:49,175 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:49,175 - py4j.clientserver - DEBUG - Command to send: c
z:py4j.reflection.TypeUtil
isInstanceOf
sorg.apache.spark.sql.AnalysisException
ro61
e

2025-03-06 17:30:49,175 - py4j.clientserver - DEBUG - Answer received: !ybfalse
2025-03-06 17:30:49,175 - py4j.clientserver - DEBUG - Command to send: r
u
py4j
rj
e

2025-03-06 17:30:49,175 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,175 - py4j.clientserver - DEBUG - Command to send: r
u
py4j.reflection
rj
e

2025-03-06 17:30:49,178 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,178 - py4j.clientserver - DEBUG - Command to send: r
u
py4j.reflection.TypeUtil
rj
e

2025-03-06 17:30:49,180 - py4j.clientserver - DEBUG - Answer received: !ycpy4j.reflection.TypeUtil
2025-03-06 17:30:49,180 - py4j.clientserver - DEBUG - Command to send: r
m
py4j.reflection.TypeUtil
isInstanceOf
e

2025-03-06 17:30:49,181 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:49,181 - py4j.clientserver - DEBUG - Command to send: c
z:py4j.reflection.TypeUtil
isInstanceOf
sorg.apache.spark.sql.streaming.StreamingQueryException
ro61
e

2025-03-06 17:30:49,182 - py4j.clientserver - DEBUG - Answer received: !ybfalse
2025-03-06 17:30:49,182 - py4j.clientserver - DEBUG - Command to send: r
u
py4j
rj
e

2025-03-06 17:30:49,184 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,185 - py4j.clientserver - DEBUG - Command to send: r
u
py4j.reflection
rj
e

2025-03-06 17:30:49,185 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,185 - py4j.clientserver - DEBUG - Command to send: r
u
py4j.reflection.TypeUtil
rj
e

2025-03-06 17:30:49,186 - py4j.clientserver - DEBUG - Answer received: !ycpy4j.reflection.TypeUtil
2025-03-06 17:30:49,186 - py4j.clientserver - DEBUG - Command to send: r
m
py4j.reflection.TypeUtil
isInstanceOf
e

2025-03-06 17:30:49,187 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:49,187 - py4j.clientserver - DEBUG - Command to send: c
z:py4j.reflection.TypeUtil
isInstanceOf
sorg.apache.spark.sql.execution.QueryExecutionException
ro61
e

2025-03-06 17:30:49,188 - py4j.clientserver - DEBUG - Answer received: !ybfalse
2025-03-06 17:30:49,189 - py4j.clientserver - DEBUG - Command to send: r
u
py4j
rj
e

2025-03-06 17:30:49,190 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,191 - py4j.clientserver - DEBUG - Command to send: r
u
py4j.reflection
rj
e

2025-03-06 17:30:49,192 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,192 - py4j.clientserver - DEBUG - Command to send: r
u
py4j.reflection.TypeUtil
rj
e

2025-03-06 17:30:49,192 - py4j.clientserver - DEBUG - Answer received: !ycpy4j.reflection.TypeUtil
2025-03-06 17:30:49,192 - py4j.clientserver - DEBUG - Command to send: r
m
py4j.reflection.TypeUtil
isInstanceOf
e

2025-03-06 17:30:49,193 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:49,194 - py4j.clientserver - DEBUG - Command to send: c
z:py4j.reflection.TypeUtil
isInstanceOf
sjava.lang.NumberFormatException
ro61
e

2025-03-06 17:30:49,194 - py4j.clientserver - DEBUG - Answer received: !ybfalse
2025-03-06 17:30:49,194 - py4j.clientserver - DEBUG - Command to send: r
u
py4j
rj
e

2025-03-06 17:30:49,197 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,198 - py4j.clientserver - DEBUG - Command to send: r
u
py4j.reflection
rj
e

2025-03-06 17:30:49,198 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,198 - py4j.clientserver - DEBUG - Command to send: r
u
py4j.reflection.TypeUtil
rj
e

2025-03-06 17:30:49,198 - py4j.clientserver - DEBUG - Answer received: !ycpy4j.reflection.TypeUtil
2025-03-06 17:30:49,199 - py4j.clientserver - DEBUG - Command to send: r
m
py4j.reflection.TypeUtil
isInstanceOf
e

2025-03-06 17:30:49,199 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:49,199 - py4j.clientserver - DEBUG - Command to send: c
z:py4j.reflection.TypeUtil
isInstanceOf
sjava.lang.IllegalArgumentException
ro61
e

2025-03-06 17:30:49,200 - py4j.clientserver - DEBUG - Answer received: !ybfalse
2025-03-06 17:30:49,201 - py4j.clientserver - DEBUG - Command to send: r
u
py4j
rj
e

2025-03-06 17:30:49,203 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,203 - py4j.clientserver - DEBUG - Command to send: r
u
py4j.reflection
rj
e

2025-03-06 17:30:49,205 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,205 - py4j.clientserver - DEBUG - Command to send: r
u
py4j.reflection.TypeUtil
rj
e

2025-03-06 17:30:49,205 - py4j.clientserver - DEBUG - Answer received: !ycpy4j.reflection.TypeUtil
2025-03-06 17:30:49,206 - py4j.clientserver - DEBUG - Command to send: r
m
py4j.reflection.TypeUtil
isInstanceOf
e

2025-03-06 17:30:49,206 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:49,206 - py4j.clientserver - DEBUG - Command to send: c
z:py4j.reflection.TypeUtil
isInstanceOf
sjava.lang.ArithmeticException
ro61
e

2025-03-06 17:30:49,207 - py4j.clientserver - DEBUG - Answer received: !ybfalse
2025-03-06 17:30:49,208 - py4j.clientserver - DEBUG - Command to send: r
u
py4j
rj
e

2025-03-06 17:30:49,210 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,210 - py4j.clientserver - DEBUG - Command to send: r
u
py4j.reflection
rj
e

2025-03-06 17:30:49,211 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,211 - py4j.clientserver - DEBUG - Command to send: r
u
py4j.reflection.TypeUtil
rj
e

2025-03-06 17:30:49,212 - py4j.clientserver - DEBUG - Answer received: !ycpy4j.reflection.TypeUtil
2025-03-06 17:30:49,212 - py4j.clientserver - DEBUG - Command to send: r
m
py4j.reflection.TypeUtil
isInstanceOf
e

2025-03-06 17:30:49,212 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:49,212 - py4j.clientserver - DEBUG - Command to send: c
z:py4j.reflection.TypeUtil
isInstanceOf
sjava.lang.UnsupportedOperationException
ro61
e

2025-03-06 17:30:49,213 - py4j.clientserver - DEBUG - Answer received: !ybfalse
2025-03-06 17:30:49,213 - py4j.clientserver - DEBUG - Command to send: r
u
py4j
rj
e

2025-03-06 17:30:49,216 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,216 - py4j.clientserver - DEBUG - Command to send: r
u
py4j.reflection
rj
e

2025-03-06 17:30:49,216 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,216 - py4j.clientserver - DEBUG - Command to send: r
u
py4j.reflection.TypeUtil
rj
e

2025-03-06 17:30:49,216 - py4j.clientserver - DEBUG - Answer received: !ycpy4j.reflection.TypeUtil
2025-03-06 17:30:49,216 - py4j.clientserver - DEBUG - Command to send: r
m
py4j.reflection.TypeUtil
isInstanceOf
e

2025-03-06 17:30:49,216 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:49,220 - py4j.clientserver - DEBUG - Command to send: c
z:py4j.reflection.TypeUtil
isInstanceOf
sjava.lang.ArrayIndexOutOfBoundsException
ro61
e

2025-03-06 17:30:49,220 - py4j.clientserver - DEBUG - Answer received: !ybfalse
2025-03-06 17:30:49,221 - py4j.clientserver - DEBUG - Command to send: r
u
py4j
rj
e

2025-03-06 17:30:49,224 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,224 - py4j.clientserver - DEBUG - Command to send: r
u
py4j.reflection
rj
e

2025-03-06 17:30:49,225 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,225 - py4j.clientserver - DEBUG - Command to send: r
u
py4j.reflection.TypeUtil
rj
e

2025-03-06 17:30:49,225 - py4j.clientserver - DEBUG - Answer received: !ycpy4j.reflection.TypeUtil
2025-03-06 17:30:49,225 - py4j.clientserver - DEBUG - Command to send: r
m
py4j.reflection.TypeUtil
isInstanceOf
e

2025-03-06 17:30:49,226 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:49,226 - py4j.clientserver - DEBUG - Command to send: c
z:py4j.reflection.TypeUtil
isInstanceOf
sjava.time.DateTimeException
ro61
e

2025-03-06 17:30:49,227 - py4j.clientserver - DEBUG - Answer received: !ybfalse
2025-03-06 17:30:49,227 - py4j.clientserver - DEBUG - Command to send: r
u
py4j
rj
e

2025-03-06 17:30:49,229 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,229 - py4j.clientserver - DEBUG - Command to send: r
u
py4j.reflection
rj
e

2025-03-06 17:30:49,229 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,229 - py4j.clientserver - DEBUG - Command to send: r
u
py4j.reflection.TypeUtil
rj
e

2025-03-06 17:30:49,231 - py4j.clientserver - DEBUG - Answer received: !ycpy4j.reflection.TypeUtil
2025-03-06 17:30:49,231 - py4j.clientserver - DEBUG - Command to send: r
m
py4j.reflection.TypeUtil
isInstanceOf
e

2025-03-06 17:30:49,232 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:49,232 - py4j.clientserver - DEBUG - Command to send: c
z:py4j.reflection.TypeUtil
isInstanceOf
sorg.apache.spark.SparkRuntimeException
ro61
e

2025-03-06 17:30:49,233 - py4j.clientserver - DEBUG - Answer received: !ybfalse
2025-03-06 17:30:49,233 - py4j.clientserver - DEBUG - Command to send: r
u
py4j
rj
e

2025-03-06 17:30:49,235 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,235 - py4j.clientserver - DEBUG - Command to send: r
u
py4j.reflection
rj
e

2025-03-06 17:30:49,237 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,237 - py4j.clientserver - DEBUG - Command to send: r
u
py4j.reflection.TypeUtil
rj
e

2025-03-06 17:30:49,238 - py4j.clientserver - DEBUG - Answer received: !ycpy4j.reflection.TypeUtil
2025-03-06 17:30:49,238 - py4j.clientserver - DEBUG - Command to send: r
m
py4j.reflection.TypeUtil
isInstanceOf
e

2025-03-06 17:30:49,238 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:49,238 - py4j.clientserver - DEBUG - Command to send: c
z:py4j.reflection.TypeUtil
isInstanceOf
sorg.apache.spark.SparkUpgradeException
ro61
e

2025-03-06 17:30:49,238 - py4j.clientserver - DEBUG - Answer received: !ybfalse
2025-03-06 17:30:49,238 - py4j.clientserver - DEBUG - Command to send: c
o61
getCause
e

2025-03-06 17:30:49,238 - py4j.clientserver - DEBUG - Answer received: !yn
2025-03-06 17:30:49,238 - py4j.clientserver - DEBUG - Command to send: r
u
org
rj
e

2025-03-06 17:30:49,243 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,243 - py4j.clientserver - DEBUG - Command to send: r
u
org.apache
rj
e

2025-03-06 17:30:49,244 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,244 - py4j.clientserver - DEBUG - Command to send: r
u
org.apache.spark
rj
e

2025-03-06 17:30:49,245 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,245 - py4j.clientserver - DEBUG - Command to send: r
u
org.apache.spark.util
rj
e

2025-03-06 17:30:49,245 - py4j.clientserver - DEBUG - Answer received: !yp
2025-03-06 17:30:49,246 - py4j.clientserver - DEBUG - Command to send: r
u
org.apache.spark.util.Utils
rj
e

2025-03-06 17:30:49,246 - py4j.clientserver - DEBUG - Answer received: !ycorg.apache.spark.util.Utils
2025-03-06 17:30:49,247 - py4j.clientserver - DEBUG - Command to send: r
m
org.apache.spark.util.Utils
exceptionString
e

2025-03-06 17:30:49,247 - py4j.clientserver - DEBUG - Answer received: !ym
2025-03-06 17:30:49,248 - py4j.clientserver - DEBUG - Command to send: c
z:org.apache.spark.util.Utils
exceptionString
ro61
e

2025-03-06 17:30:49,248 - py4j.clientserver - DEBUG - Answer received: !ysjava.lang.UnsatisfiedLinkError: 'boolean org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(java.lang.String, int)'\r\n	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)\r\n	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:793)\r\n	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1249)\r\n	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1454)\r\n	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:601)\r\n	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972)\r\n	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014)\r\n	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:761)\r\n	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972)\r\n	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014)\r\n	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:334)\r\n	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:404)\r\n	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377)\r\n	at org.apache.parquet.hadoop.ParquetOutputCommitter.commitJob(ParquetOutputCommitter.java:48)\r\n	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:192)\r\n	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$writeAndCommit$3(FileFormatWriter.scala:275)\r\n	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:552)\r\n	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:275)\r\n	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:304)\r\n	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:190)\r\n	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:190)\r\n	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\r\n	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\r\n	at org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\r\n	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\r\n	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\r\n	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\r\n	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\r\n	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\r\n	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\r\n	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\r\n	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\r\n	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\r\n	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\r\n	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\r\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\r\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\r\n	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\r\n	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\r\n	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\r\n	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\r\n	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\r\n	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\r\n	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\r\n	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869)\r\n	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391)\r\n	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364)\r\n	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:243)\r\n	at org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:802)\r\n	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n	at java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n	at py4j.Gateway.invoke(Gateway.java:282)\r\n	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n	at py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n	at java.base/java.lang.Thread.run(Thread.java:834)\r\n
2025-03-06 17:30:49,249 - py4j.clientserver - DEBUG - Command to send: c
o61
toString
e

2025-03-06 17:30:49,250 - py4j.clientserver - DEBUG - Answer received: !ysjava.lang.UnsatisfiedLinkError: 'boolean org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(java.lang.String, int)'
2025-03-06 17:30:49,254 - py4j.clientserver - DEBUG - Command to send: p
ro61
e

2025-03-06 17:30:49,255 - py4j.clientserver - DEBUG - Answer received: !ysjava.lang.UnsatisfiedLinkError: 'boolean org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(java.lang.String, int)'\r\n	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)\r\n	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:793)\r\n	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1249)\r\n	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1454)\r\n	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:601)\r\n	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972)\r\n	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014)\r\n	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:761)\r\n	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972)\r\n	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014)\r\n	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:334)\r\n	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:404)\r\n	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377)\r\n	at org.apache.parquet.hadoop.ParquetOutputCommitter.commitJob(ParquetOutputCommitter.java:48)\r\n	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:192)\r\n	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$writeAndCommit$3(FileFormatWriter.scala:275)\r\n	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:552)\r\n	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:275)\r\n	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:304)\r\n	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:190)\r\n	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:190)\r\n	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\r\n	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\r\n	at org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\r\n	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\r\n	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\r\n	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\r\n	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\r\n	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\r\n	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\r\n	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\r\n	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\r\n	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\r\n	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\r\n	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\r\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\r\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\r\n	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\r\n	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\r\n	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\r\n	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\r\n	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\r\n	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\r\n	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\r\n	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869)\r\n	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391)\r\n	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364)\r\n	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:243)\r\n	at org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:802)\r\n	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n	at java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n	at py4j.Gateway.invoke(Gateway.java:282)\r\n	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n	at py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n	at java.base/java.lang.Thread.run(Thread.java:834)\r\n
